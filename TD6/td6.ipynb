{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65a3a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "with open(\"requetes_as_they_are.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        questions.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba7b777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ponctuations = [\n",
    "    \".\", \",\", \"?\"\n",
    "    ]\n",
    "\n",
    "articles_fr = [\n",
    "    \"le\", \"la\", \"les\",        # Définis\n",
    "    \"un\", \"une\", \"des\",       # Indéfinis\n",
    "    \"du\", \"de la\", \"de l’\", \"des\",  # Partitifs\n",
    "    \"l’\",                     # Élision\n",
    "    \"au\", \"aux\", \"à la\", \"à l’\",  # Contractions avec \"à\"\n",
    "    \"du\", \"des\", \"de la\", \"de l’\",  # Contractions avec \"de\"\n",
    "    \"de\", \"d'\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3953bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr_core_news_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstop_words\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STOP_WORDS \u001b[38;5;28;01mas\u001b[39;00m fr_stop\n\u001b[0;32m      4\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(fr_stop)\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_package(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload(vocab\u001b[38;5;241m=\u001b[39mvocab, disable\u001b[38;5;241m=\u001b[39mdisable, enable\u001b[38;5;241m=\u001b[39menable, exclude\u001b[38;5;241m=\u001b[39mexclude, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\fr_core_news_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_init_py(\u001b[38;5;18m__file__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    683\u001b[0m     data_path,\n\u001b[0;32m    684\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m    685\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    686\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[0;32m    687\u001b[0m     enable\u001b[38;5;241m=\u001b[39menable,\n\u001b[0;32m    688\u001b[0m     exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m    689\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    690\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\util.py:547\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    538\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m    539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[0;32m    540\u001b[0m     config,\n\u001b[0;32m    541\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    546\u001b[0m )\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mfrom_disk(model_path, exclude\u001b[38;5;241m=\u001b[39mexclude, overrides\u001b[38;5;241m=\u001b[39moverrides)\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\language.py:2246\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m   2244\u001b[0m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m   2245\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(exclude) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2246\u001b[0m util\u001b[38;5;241m.\u001b[39mfrom_disk(path, deserializers, exclude)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   2248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_link_components()\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\util.py:1390\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1388\u001b[0m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[1;32m-> 1390\u001b[0m         reader(path \u001b[38;5;241m/\u001b[39m key)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\language.py:2232\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m   2230\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta.json\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m deserialize_meta  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m deserialize_vocab  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m-> 2232\u001b[0m deserializers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mfrom_disk(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   2233\u001b[0m     p, exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2234\u001b[0m )\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, proc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components:\n\u001b[0;32m   2236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m exclude:\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\tokenizer.pyx:787\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\tokenizer.pyx:855\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.from_bytes\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\tokenizer.pyx:131\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.rules.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\tokenizer.pyx:580\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer._load_special_cases\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\tokenizer.pyx:615\u001b[0m, in \u001b[0;36mspacy.tokenizer.Tokenizer.add_special_case\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\vocab.pyx:319\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.make_fused_token\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\vocab.pyx:219\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.get_by_orth\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\vocab.pyx:234\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab._new_lexeme\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ntich\\anaconda3\\Lib\\site-packages\\spacy\\lang\\lex_attrs.py:145\u001b[0m, in \u001b[0;36mlower\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlower\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m string\u001b[38;5;241m.\u001b[39mlower()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "stopwords = list(fr_stop)\n",
    "clean_requetes = []\n",
    "for requete in questions:\n",
    "    doc = nlp(requete)\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    clean_words = []\n",
    "    clean_requete = \"\"\n",
    "    for token in tokens:\n",
    "        if token not in stopwords and token not in ponctuations:\n",
    "            clean_words.append(token)\n",
    "            clean_requete += token + \" \"\n",
    "\n",
    "    clean_requetes.append(clean_requete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde76a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_cles_requete = [\n",
    "        \"rubriques\", \"articles\", \"article\", \"bulletins\", \"recherches\"\n",
    "]\n",
    "\n",
    "mots_cles_articles = [\n",
    "        \"qui parlent de la ville\", \"mais qui ne parlent\", \"portant sur\", \"portent sur\", \"traitant\", \"évoquant\", \n",
    "        \"évoquent la ville\",\"et qui évoquent\", \"évoquent\", \"possédant le mot\", \"et parlant\", \"parlant\", \"mentionnant\", \n",
    "        \" liés à\", \"dans le domaine\", \"et qui contiennent les mots\", \"contiennent les mots\", \"le contenu parle\", \n",
    "        \"à propos\", \"sur\", \"qui concernent\", \"parlent\", \"qui parle\", \"contenant les mots\",  \"portant\",\n",
    "    ]\n",
    "\n",
    "mots_cles_rubrique = [\n",
    "         \"et\", \"parlant\", \"mentionnant\", \"mais\", \"qui\" #ou fin de phrase\n",
    "    ]\n",
    "\n",
    "mots_cles_titre = [\n",
    "        \"est\", \"contient\", \"évoque\", \"traite\"\n",
    "    ]\n",
    "\n",
    "mot_cles_images = [\n",
    "        \"avec des images\", \"contenant une image\", \"et qui ont des images\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e059635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifie_image(requete, mot_cles_images):\n",
    "    for mot in mot_cles_images:\n",
    "        if mot in requete:\n",
    "            requete = requete.replace(mot, \"\")\n",
    "            return requete, True\n",
    "    return requete, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b78ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher post traitement des images\n",
    "with open(\"requetes_as_they_are.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()  \n",
    "    #print(list_of_strings)  \n",
    "\n",
    "with open(\"post_image.txt\", 'w', encoding='utf-8') as f2:\n",
    "        with open(\"results_images.txt\", 'w', encoding='utf-8') as f3:\n",
    "            for requete_test in list_of_strings:\n",
    "                #print(requete_test)\n",
    "                requete_test = requete_test.lower()\n",
    "                requete_test = requete_test.replace(\"?\", \"\").replace(\".\", \"\").replace(\"’\", \"'\")\n",
    "                post_images, image_info = identifie_image(requete_test, mot_cles_images)\n",
    "                f2.write(post_images)\n",
    "                if image_info == True: image_info = \"True\"\n",
    "                else: image_info = \"False\"\n",
    "                f3.write(image_info + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2edcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifie_return(requete, mots_cles_requete):\n",
    "    positions = {}\n",
    "    for mot in mots_cles_requete:\n",
    "        index = requete.find(mot)\n",
    "        if index != -1:\n",
    "            positions[mot] = index\n",
    "\n",
    "    # Trie les mots par position d'apparition dans la requête\n",
    "    mot_le_plus_tot = min(positions, key=positions.get)\n",
    "    requete = requete[positions[mot_le_plus_tot] + len(mot_le_plus_tot):]\n",
    "    return requete, mot_le_plus_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3053f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher resultats post traitement return value\n",
    "with open(\"post_image.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()  \n",
    "    #print(list_of_strings)  \n",
    "\n",
    "with open(\"post_return.txt\", 'w', encoding='utf-8') as f2:\n",
    "        with open(\"results_return.txt\", 'w', encoding='utf-8') as f3:\n",
    "            for requete_test in list_of_strings:\n",
    "                post_return, result_return = identifie_return(requete_test, mots_cles_requete)\n",
    "                f2.write(post_return)\n",
    "                f3.write(result_return + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8584350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifie_rubrique(requete, mots_cles_rubrique):\n",
    "    if \"rubrique\" not in requete:\n",
    "        return requete, None, None  # \"rubrique\" absent\n",
    "\n",
    "    # Position du mot \"rubrique\"\n",
    "    start_index = requete.find(\"rubrique\") + len(\"rubrique \")\n",
    "\n",
    "    # Texte après \"rubrique\"\n",
    "    sous_texte = requete[start_index:]\n",
    "\n",
    "    # Trouver le mot-clé suivant\n",
    "    min_index = len(sous_texte)  # valeur maximale par défaut\n",
    "    for mot in mots_cles_rubrique:\n",
    "        index = sous_texte.find(mot)\n",
    "        if index != -1 and index < min_index:\n",
    "            min_index = index\n",
    "\n",
    "    resultat = sous_texte[:min_index]\n",
    "    resultat = resultat.replace(\"est \", \"\").replace(\"'\", \"\")\n",
    "    if \"ou\" in resultat:\n",
    "        resultat = resultat.split(\" ou \")\n",
    "        op_rubrique = \"ou\"\n",
    "    else:\n",
    "        op_rubrique = None\n",
    "\n",
    "    requete_reste = requete[:start_index - len(\"rubrique \")] + sous_texte[min_index:]\n",
    "    \n",
    "    return requete_reste, resultat, op_rubrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requete_reste:  qui parlent des systèmes embarqués dans la \n",
      "resultat: horizons enseignement\n",
      "op_rub: None\n"
     ]
    }
   ],
   "source": [
    "requete = \" qui parlent des systèmes embarqués dans la rubrique horizons enseignement\"\n",
    "requete_reste, resultat, op_rub = identifie_rubrique(requete, mots_cles_rubrique)\n",
    "print(\"requete_reste:\", requete_reste)\n",
    "print(\"resultat:\", resultat)\n",
    "print(\"op_rub:\", op_rub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher resultats post traitement rubrique\n",
    "with open(\"post_return.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()  \n",
    "    #print(list_of_strings)  \n",
    "\n",
    "with open(\"post_rubrique.txt\", 'w', encoding='utf-8') as f2:\n",
    "        with open(\"results_rubrique.txt\", 'w', encoding='utf-8') as f3:\n",
    "            for requete_test in list_of_strings:\n",
    "                post_rubrique, result_rubrique, op_rubrique = identifie_rubrique(requete_test, mots_cles_rubrique)\n",
    "                written_post = post_rubrique.replace(\"\\n\", \"\").replace(\"\\n\", \"\") + \"\\n\"\n",
    "                if written_post != \"\\n\" and written_post != \"\":\n",
    "                    f2.write(written_post)\n",
    "                if result_rubrique is None:\n",
    "                    result_rubrique = \"None\"\n",
    "                elif isinstance(result_rubrique, list):\n",
    "                    result_rubrique = \"\\t\".join(result_rubrique)\n",
    "                if op_rubrique is None:\n",
    "                    op_rubrique = \"op_None\"\n",
    "                f3.write(result_rubrique + \"\\t\" + op_rubrique + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae47f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_cles_titre = [\n",
    "        \"est\", \"contient\", \"évoque\", \"traite\"\n",
    "    ]\n",
    "\n",
    "def identifie_titres(requete, mots_cles_titre):\n",
    "    if \"titre\" not in requete:\n",
    "        return requete, None, None  # \"titre\" absent\n",
    "\n",
    "    # cas très niche: contenant mot congres dans titre\n",
    "    if \"contenant\" in requete and \"dans titre\" in requete:\n",
    "        start_index = requete.find(\"contenant\") + len(\"contenant\")\n",
    "        sous_texte = requete[start_index:]\n",
    "        min_index = sous_texte.find(\"dans titre\")\n",
    "        resultat = sous_texte[:min_index]\n",
    "        resultat = resultat.replace(\"mot \", \"\").replace(\"terme \", \"\")\n",
    "        requete_reste = requete[: requete.find(\"contenant\")]\n",
    "        return requete_reste, resultat, None\n",
    "    #les autres cas\n",
    "    else:\n",
    "        # Position du mot \"titre\"\n",
    "        start_index = requete.find(\"titre\") + len(\"titre \")\n",
    "\n",
    "        # Texte après \"titre\"\n",
    "        sous_texte = requete[start_index:]\n",
    "\n",
    "        # Ou on arrete de regarder les titres\n",
    "        min_index = len(sous_texte)  # valeur maximale par défaut\n",
    "        if \" ou \" in sous_texte:\n",
    "            min_index = sous_texte.find(\"ou\")\n",
    "        resultat = sous_texte[:min_index]\n",
    "    #requete_reste = requete.replace(resultat, \"\")\n",
    "\n",
    "    #sous_texte = partie qui contient le titre. maintenant, il faut le nettoyer et enlever les parties inutiles\n",
    "    for mot in mots_cles_titre:\n",
    "        resultat = resultat.replace(mot, \"\")\n",
    "    resultat = resultat.replace(\"mot \", \"\").replace(\"terme \", \"\")\n",
    "\n",
    "    #vérifier si il y a un \"et\" dans le titre\n",
    "    op_titre = None\n",
    "    if \"et\" in resultat:\n",
    "        resultat = resultat.split(\" et \")\n",
    "        op_titre = \"et\"\n",
    "    if isinstance(resultat, list):\n",
    "        for res in resultat:\n",
    "            res.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"  \", \" \")\n",
    "    elif resultat in \"    \\t  \\n\":\n",
    "        resultat = None\n",
    "    else:\n",
    "        resultat = resultat.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"  \", \" \")\n",
    " \n",
    "    requete_reste = requete[:start_index - len(\"titre \")] + requete[min_index + len(sous_texte):]\n",
    "    requete_reste = requete_reste.replace(\"dont\", \"\").replace(\"dont\", \"\")\n",
    "    \n",
    "    return requete_reste, resultat, op_titre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9861b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "requete_result:   \n",
      "resultat:  chimie\n",
      "op_titre: None\n"
     ]
    }
   ],
   "source": [
    "requete = \" dont le titre contient le mot chimie\"\n",
    "for article in articles_fr:\n",
    "    requete = requete.replace(article + \" \", \"\")\n",
    "    \n",
    "requete_result, resultat, op_titre = identifie_titres(requete, mots_cles_titre)\n",
    "print(\"-----------------------------------\")\n",
    "print(\"requete_result:\", requete_result)\n",
    "print(\"resultat:\", resultat)\n",
    "print(\"op_titre:\", op_titre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"post_rubrique.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()  \n",
    "    #print(list_of_strings)  \n",
    "\n",
    "with open(\"post_titre.txt\", 'w', encoding='utf-8') as f2:\n",
    "        with open(\"results_titre.txt\", 'w', encoding='utf-8') as f3:\n",
    "            for requete_test in list_of_strings:\n",
    "                #print(requete_test)\n",
    "                \n",
    "                for article in articles_fr:\n",
    "                    requete_test = requete_test.replace( \" \" + article + \" \", \" \")\n",
    "                \n",
    "                post_titres, titre, op_titre = identifie_titres(requete_test, mots_cles_titre)\n",
    "                f2.write(post_titres)\n",
    "                if titre == None: titre = \"None\"\n",
    "                if op_titre == None: op_titre = \"None\"\n",
    "                if isinstance(titre, list):\n",
    "                    for i in titre:\n",
    "                        f3.write(i + \" \")\n",
    "                    f3.write(\"\\n\")\n",
    "                else:\n",
    "                    f3.write(titre + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7c5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def premier_index_result(texte, mots_cles_dates):\n",
    "    # Cherche l'index de chaque mot-clé dans le texte\n",
    "    indices = []\n",
    "    for mot in mots_cles_dates:\n",
    "        idx = texte.find(mot)\n",
    "        if idx != -1:\n",
    "            indices.append(idx)\n",
    "    # Cherche l'index du premier chiffre\n",
    "    for i, c in enumerate(texte):\n",
    "        if c.isdigit():\n",
    "            indices.append(i)\n",
    "            break\n",
    "    if indices:\n",
    "        ind = min(indices)\n",
    "        return ind, texte[ind:]\n",
    "    else:\n",
    "        return None, texte\n",
    "    \n",
    "def last_index_result(texte, fin_dates):\n",
    "    fin_dates = [\n",
    "    \"évoquant\", \"sur\", \"parlant\", \"portant\", \"parlent\"\n",
    "    ]\n",
    "    indices = []\n",
    "    for mot in fin_dates:\n",
    "        idx = texte.find(mot)\n",
    "        if idx != -1:\n",
    "            indices.append(idx)\n",
    "    if indices:\n",
    "        ind = min(indices)\n",
    "        print(ind, texte[:ind])\n",
    "        return ind, texte[:ind]\n",
    "    else:\n",
    "        return None, texte\n",
    "\n",
    "def contient_nombre(requete):\n",
    "    return any(token.isdigit() or \"/\" in token for token in requete.split())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(date_string):\n",
    "    format_normalise_date = {\"j\": None, \"m\": None, \"a\": None}\n",
    "\n",
    "    mois = [\"janvier\", \"février\", \"mars\", \"avril\", \"mai\", \"juin\", \"juillet\",\n",
    "        \"août\", \"septembre\", \"octobre\", \"novembre\", \"décembre\"]\n",
    "    date_string = date_string.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"  \", \" \")\n",
    "    if \"/\" in date_string:\n",
    "        date = date_string.split(\"/\")\n",
    "        format_normalise_date[\"j\"] = date[0].replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "        format_normalise_date[\"m\"] = date[1].replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "        format_normalise_date[\"a\"] = date[2].replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "    else:\n",
    "        date = date_string.split(\" \")\n",
    "        for date_info in date:\n",
    "            if date_info.isdigit():\n",
    "                if len(date_info) == 4:\n",
    "                    format_normalise_date[\"a\"] = date_info.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "                else:\n",
    "                    format_normalise_date[\"j\"] = date_info.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            else:\n",
    "                if date_info in mois:\n",
    "                    mois_value = mois.index(date_info) + 1\n",
    "                    if mois_value < 10:\n",
    "                        format_normalise_date[\"m\"] = \"0\" + str(mois_value)\n",
    "                    else:\n",
    "                        format_normalise_date[\"m\"] = str(mois_value)\n",
    "\n",
    "    return format_normalise_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c83459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mots_cles_dates = [\n",
    "\"parus\", \"publiés\" , \"datés\",\n",
    "\"à partir\", \"l'année\", \"écrits\", \"date\", \"datent\", \"mois\"\n",
    "]\n",
    "\n",
    "mois = [\"janvier\", \"février\", \"mars\", \"avril\", \"mai\", \"juin\", \"juillet\",\n",
    "        \"août\", \"septembre\", \"octobre\", \"novembre\", \"décembre\"]\n",
    "\n",
    "fin_dates = [\n",
    "    \"évoquant\", \"sur\", \"parlant\", \"portant\", \"parlent\"\n",
    "    ]\n",
    "\n",
    "def identifie_dates(requete, mots_cles_dates):\n",
    "    resultat = {\"début\": None, \"fin\": None, \"précis\": None, \"not\": None}\n",
    "    #vérifier si il y a une date dans la requete\n",
    "    if not contient_nombre(requete):\n",
    "        return requete, resultat\n",
    "    \n",
    "    #début et fin de partie date\n",
    "    idx_debut, sous_texte = premier_index_result(requete, mots_cles_dates)\n",
    "    idx_fin, sous_texte =  last_index_result(sous_texte, fin_dates)\n",
    "    if idx_debut is None:\n",
    "        idx_debut = 0\n",
    "    if idx_fin is None:\n",
    "        idx_fin = -1\n",
    "    #clean up requete_reste\n",
    "    #print(requete[idx_fin:])\n",
    "    #print(requete[:idx_debut])\n",
    "    #requete_reste = requete[:idx_debut] + requete[idx_fin:]\n",
    "    requete_reste = requete.replace(sous_texte, \"\")\n",
    "\n",
    "    #clean up sous_texte\n",
    "    mots_trash = [\"qui\", \"dont\", \"mais\"]\n",
    "    for mot in mots_trash:\n",
    "        sous_texte = sous_texte.replace(mot, \"\")\n",
    "    \n",
    "    #3 cas possibles:\n",
    "    #cas niche: on veut pas une date précise\n",
    "    if \"pas\" in sous_texte:\n",
    "        pas_indx = sous_texte.find(\"pas\") + len(\"pas\")\n",
    "        not_date = sous_texte[pas_indx:]\n",
    "        resultat[\"not\"] = clean_date(not_date)\n",
    "        sous_texte = sous_texte[:pas_indx - len(\"pas\")]\n",
    "\n",
    "    #cas 1: date entre deux dates\n",
    "         #parus entre .... et .... / écrits entre .... et .... / publiés entre .... et ....\n",
    "    if \"entre\" in sous_texte:\n",
    "        sous_texte = sous_texte[sous_texte.find(\"entre\") + len(\"entre\"):]\n",
    "        result_temp = sous_texte.split(\"et\")\n",
    "        #print(result_temp)\n",
    "        resultat[\"début\"] = clean_date(result_temp[0])\n",
    "        resultat[\"fin\"] = clean_date(result_temp[1])\n",
    "\n",
    "\n",
    "    #cas 2: date à partir d'une date\n",
    "        #datés à partir de .... / à partir ... / écrits après / date d'après ... / publiés après ...\n",
    "    elif \"à partir\" in sous_texte or \"après\" in sous_texte:\n",
    "        idx_à_partir = sous_texte.find(\"à partir\")\n",
    "        idx_apres = sous_texte.find(\"après\")\n",
    "        if idx_à_partir == -1:\n",
    "            start_apres = idx_apres + len(\"après\")\n",
    "        else:\n",
    "            start_apres = idx_à_partir + len(\"à partir\")\n",
    "            \n",
    "        resultat[\"début\"] = clean_date(sous_texte[start_apres:])\n",
    "\n",
    "    #cas 3: date précise (utiliser else)\n",
    "        #directement date / publiés mois ... /\n",
    "    else:\n",
    "        resultat[\"précis\"] = clean_date(sous_texte)\n",
    "\n",
    "    \n",
    "    return requete_reste, resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c460c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      " qui parlent systèmes embarqués dans \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent systèmes embarqués dans \n",
      "\n",
      "--------------------\n",
      " qui parlent cuisine moléculaire\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent cuisine moléculaire\n",
      "\n",
      "--------------------\n",
      " sur réalité virtuelle \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur réalité virtuelle \n",
      "\n",
      "--------------------\n",
      " qui parlent d'airbus ou projet taxibot\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent d'airbus ou projet taxibot\n",
      "\n",
      "--------------------\n",
      " qui parlent tennis\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent tennis\n",
      "\n",
      "--------------------\n",
      " traitant lune\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  traitant lune\n",
      "\n",
      "38 parus entre 3 mars 2013 et 4 mai 2013 \n",
      "--------------------\n",
      " parus entre 3 mars 2013 et 4 mai 2013 évoquant etats-unis \n",
      "\n",
      "début {'j': '3', 'm': '03', 'a': '2013'}\n",
      "fin {'j': '4', 'm': '05', 'a': '2013'}\n",
      "précis None\n",
      "not None\n",
      "reste:  évoquant etats-unis \n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  \n",
      "\n",
      "--------------------\n",
      " parlant d'innovation\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant d'innovation\n",
      "\n",
      "--------------------\n",
      " parlant russie ou japon \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant russie ou japon \n",
      "\n",
      "5 2011 \n",
      "--------------------\n",
      " 2011 sur l'enseignement\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2011'}\n",
      "not None\n",
      "reste:  sur l'enseignement\n",
      "\n",
      "11 2014 et et \n",
      "--------------------\n",
      "   2014 et et parlant santé\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2014'}\n",
      "not None\n",
      "reste:    parlant santé\n",
      "\n",
      "--------------------\n",
      " articles parlant nutrition ou vins\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  articles parlant nutrition ou vins\n",
      "\n",
      "--------------------\n",
      " sur l'aéronautique\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur l'aéronautique\n",
      "\n",
      "--------------------\n",
      " traitant serious game et réalité virtuelle\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  traitant serious game et réalité virtuelle\n",
      "\n",
      "--------------------\n",
      " traitant d'informatique ou reseaux\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  traitant d'informatique ou reseaux\n",
      "\n",
      "--------------------\n",
      " mentionnant laboratoire\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  mentionnant laboratoire\n",
      "\n",
      "27 publiés mois novembre 2011 \n",
      "--------------------\n",
      " publiés mois novembre 2011 portant sur recherche\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': '11', 'a': '2011'}\n",
      "not None\n",
      "reste:  portant sur recherche\n",
      "\n",
      "--------------------\n",
      " sur plasturgie\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur plasturgie\n",
      "\n",
      "--------------------\n",
      " portent à fois sur nanotechnologies et microsatellites\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  portent à fois sur nanotechnologies et microsatellites\n",
      "\n",
      "--------------------\n",
      " liés à recherche scientifique publiés en février 2010\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': '02', 'a': '2010'}\n",
      "not None\n",
      "reste:  liés à recherche scientifique \n",
      "--------------------\n",
      " qui parlent d'apprentissage et \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent d'apprentissage et \n",
      "\n",
      "--------------------\n",
      " dans domaine industriel et datés à partir 2012\n",
      "\n",
      "début {'j': None, 'm': None, 'a': '2012'}\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  dans domaine industriel et \n",
      "18 mois juin 2013 et \n",
      "--------------------\n",
      " mois juin 2013 et parlant cerveau\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': '06', 'a': '2013'}\n",
      "not None\n",
      "reste:  parlant cerveau\n",
      "\n",
      "--------------------\n",
      " sur cnrs et l'innovation à partir 2013\n",
      "\n",
      "début {'j': None, 'm': None, 'a': '2013'}\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur cnrs et l'innovation \n",
      "--------------------\n",
      " sur avions\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur avions\n",
      "\n",
      "--------------------\n",
      " qui portent sur l'alimentation l'année 2013\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2013'}\n",
      "not None\n",
      "reste:  qui portent sur l'alimentation \n",
      "--------------------\n",
      "   parlant smartphones\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:    parlant smartphones\n",
      "\n",
      "--------------------\n",
      " parlant projet européen l'année 2014 \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2014'}\n",
      "not None\n",
      "reste:  parlant projet européen \n",
      "--------------------\n",
      " \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  \n",
      "\n",
      "--------------------\n",
      " parlant neurobiologie\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant neurobiologie\n",
      "\n",
      "--------------------\n",
      " possédant mot france \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  possédant mot france \n",
      "\n",
      "28 écrits en décembre 2012 qui \n",
      "--------------------\n",
      " écrits en décembre 2012 qui parlent l'environnement \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': '12', 'a': '2012'}\n",
      "not None\n",
      "reste:  parlent l'environnement \n",
      "\n",
      "--------------------\n",
      " contenant mots voitures et électrique \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  contenant mots voitures et électrique \n",
      "\n",
      "--------------------\n",
      "    qui parlent microbiologie \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:     qui parlent microbiologie \n",
      "\n",
      "33 écrits après janvier 2014 et qui \n",
      "--------------------\n",
      " écrits après janvier 2014 et qui parlent d'informatique ou télécommunications\n",
      "\n",
      "début {'j': None, 'm': '01', 'a': '2014'}\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlent d'informatique ou télécommunications\n",
      "\n",
      "9 2012 qui \n",
      "--------------------\n",
      " 2012 qui parlent l'écologie en france\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2012'}\n",
      "not None\n",
      "reste:  parlent l'écologie en france\n",
      "\n",
      "--------------------\n",
      " parlent réalité virtuelle \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlent réalité virtuelle \n",
      "\n",
      "--------------------\n",
      " trouve-t-on articles sur l'alimentation \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  trouve-t-on articles sur l'alimentation \n",
      "\n",
      "--------------------\n",
      " qui parlent soit cnrs, soit grandes écoles, mais pas centrale paris\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent soit cnrs, soit grandes écoles, mais pas centrale paris\n",
      "\n",
      "--------------------\n",
      " qui parle biologie et qui date d'après 2 juillet 2012 \n",
      "\n",
      "début {'j': '2', 'm': '07', 'a': '2012'}\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parle biologie et qui \n",
      "--------------------\n",
      " qui parlent d'innovations technologiques \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent d'innovations technologiques \n",
      "\n",
      "--------------------\n",
      "   provenant et  à propos fleurs ou arbres\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:    provenant et  à propos fleurs ou arbres\n",
      "\n",
      "--------------------\n",
      " donc et qui contiennent mots chercheurs et paris\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  donc et qui contiennent mots chercheurs et paris\n",
      "\n",
      "--------------------\n",
      " qui parlent sénégal\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent sénégal\n",
      "\n",
      "--------------------\n",
      " qui parlent d'innovation\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent d'innovation\n",
      "\n",
      "--------------------\n",
      "   qui contiennent mots ecole et polytechnique\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:    qui contiennent mots ecole et polytechnique\n",
      "\n",
      "--------------------\n",
      " provenant \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  provenant \n",
      "\n",
      "--------------------\n",
      " qui datent 1 décembre 2012 et dont \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': '1', 'm': '12', 'a': '2012'}\n",
      "not None\n",
      "reste:  qui \n",
      "--------------------\n",
      " laurent lagrost est-il cité \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  laurent lagrost est-il cité \n",
      "\n",
      "--------------------\n",
      " évoquent ville grenoble \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  évoquent ville grenoble \n",
      "\n",
      "--------------------\n",
      " parlant drones\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant drones\n",
      "\n",
      "--------------------\n",
      " parlant molécules\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant molécules\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  \n",
      "\n",
      "--------------------\n",
      " parlant d'université\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant d'université\n",
      "\n",
      "--------------------\n",
      " dont \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  dont \n",
      "\n",
      "--------------------\n",
      "   dont mais qui ne parlent pas d'ingénieurs\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:    dont mais qui ne parlent pas d'ingénieurs\n",
      "\n",
      "--------------------\n",
      " dont et qui évoquent médecine\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  dont et qui évoquent médecine\n",
      "\n",
      "--------------------\n",
      " écrits entre 2012 et 2013 mais pas mois juin\n",
      "\n",
      "début {'j': None, 'm': None, 'a': '2012'}\n",
      "fin {'j': None, 'm': None, 'a': '2013'}\n",
      "précis None\n",
      "not {'j': None, 'm': '06', 'a': None}\n",
      "reste:  \n",
      "--------------------\n",
      "     et publiés entre 30/08/2011 et 29/09/2011\n",
      "\n",
      "début {'j': '30', 'm': '08', 'a': '2011'}\n",
      "fin {'j': '29', 'm': '09', 'a': '2011'}\n",
      "précis None\n",
      "not None\n",
      "reste:      et \n",
      "--------------------\n",
      " sur changement climatique publiés après 29/09/2011\n",
      "\n",
      "début {'j': '29', 'm': '09', 'a': '2011'}\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  sur changement climatique \n",
      "--------------------\n",
      " parlent d'aviation et ont été publiés en 2015 \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2015'}\n",
      "not None\n",
      "reste:  parlent d'aviation et ont été \n",
      "--------------------\n",
      " qui parlent ville paris \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent ville paris \n",
      "\n",
      "--------------------\n",
      " impliquant cnrs et qui parlent chimie\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  impliquant cnrs et qui parlent chimie\n",
      "\n",
      "--------------------\n",
      " qui mentionnent fink\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui mentionnent fink\n",
      "\n",
      "--------------------\n",
      " parlent france et l'allemagne \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlent france et l'allemagne \n",
      "\n",
      "--------------------\n",
      " parlant l'argentine ou brésil\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  parlant l'argentine ou brésil\n",
      "\n",
      "--------------------\n",
      " qui parlent l'hydravion\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent l'hydravion\n",
      "\n",
      "--------------------\n",
      " qui parlent fauteuil roulant et qui ont pour \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent fauteuil roulant et qui ont pour \n",
      "\n",
      "18 écrits en 2012 et \n",
      "--------------------\n",
      " qui sont écrits en 2012 et parlent « chrono-environnement »\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis {'j': None, 'm': None, 'a': '2012'}\n",
      "not None\n",
      "reste:  qui sont parlent « chrono-environnement »\n",
      "\n",
      "--------------------\n",
      " qui parlent robots et chirurgiens \n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent robots et chirurgiens \n",
      "\n",
      "--------------------\n",
      " qui parlent systmes embarqués et non pas robotique\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent systmes embarqués et non pas robotique\n",
      "\n",
      "--------------------\n",
      " qui parlent alimentations ou agricultures\n",
      "\n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:  qui parlent alimentations ou agricultures\n",
      "\n",
      "--------------------\n",
      "  \n",
      "début None\n",
      "fin None\n",
      "précis None\n",
      "not None\n",
      "reste:   \n"
     ]
    }
   ],
   "source": [
    "with open(\"post_titre.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()   \n",
    "\n",
    "with open(\"post_dates.txt\", 'w', encoding='utf-8') as f2:\n",
    "    for requete_test in list_of_strings:                \n",
    "        post_date, result_dates = identifie_dates(requete_test, mots_cles_dates)\n",
    "        f2.write(post_date)\n",
    "        print(\"--------------------\")\n",
    "        print(requete_test)\n",
    "        for key, value in result_dates.items():\n",
    "            print(key, value)\n",
    "        print(\"reste:\", post_date)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "022708b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "stopwords = list(fr_stop)\n",
    "\n",
    "with open(\"post_dates.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()   \n",
    "\n",
    "with open(\"post_clean_mots.txt\", 'w', encoding='utf-8') as f2:\n",
    "    for requete_test in list_of_strings:                \n",
    "        for stop_word in stopwords:\n",
    "            requete_test = requete_test.replace(\" \" + stop_word + \" \", \" \")\n",
    "        f2.write(requete_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cb49663",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_cles_articles = [\n",
    "    \"parlent\", \"sur\", \"traitant\", \"évoquant\", \"parlant\", \"mentionnant\", \n",
    "    \"portant\", \"portent\", \"liés\", \"dans domaine\", \"mot\", \"mots\", \"parle\",\n",
    "    \"à propos\", \"évoquent\", \"impliquant\", \"mentionnent\"\n",
    "]\n",
    "\n",
    "niche = \"cité\"\n",
    "\n",
    "def identifie_mots_cles(requete, mots_cles_articles):\n",
    "    for mot in mots_cles_articles:\n",
    "        if mot in requete:\n",
    "            sous_text = requete[requete.find(mot) + len(mot):]\n",
    "            return requete, sous_text, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a98e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requete:  qui parlent systèmes embarqués dans \n",
      "\n",
      "(' qui parlent systèmes embarqués dans \\n', ' systèmes embarqués dans \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent cuisine moléculaire\n",
      "\n",
      "(' qui parlent cuisine moléculaire\\n', ' cuisine moléculaire\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  sur réalité virtuelle \n",
      "\n",
      "(' sur réalité virtuelle \\n', ' réalité virtuelle \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent d'airbus ou projet taxibot\n",
      "\n",
      "(\" qui parlent d'airbus ou projet taxibot\\n\", \" d'airbus ou projet taxibot\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent tennis\n",
      "\n",
      "(' qui parlent tennis\\n', ' tennis\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  traitant lune\n",
      "\n",
      "(' traitant lune\\n', ' lune\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  évoquant etats-unis \n",
      "\n",
      "(' évoquant etats-unis \\n', ' etats-unis \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  \n",
      "\n",
      "None\n",
      "-------------------------------------------------\n",
      "requete:  parlant d'innovation\n",
      "\n",
      "(\" parlant d'innovation\\n\", \" d'innovation\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant russie ou japon \n",
      "\n",
      "(' parlant russie ou japon \\n', ' russie ou japon \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  sur l'enseignement\n",
      "\n",
      "(\" sur l'enseignement\\n\", \" l'enseignement\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:    parlant santé\n",
      "\n",
      "('   parlant santé\\n', ' santé\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  articles parlant nutrition ou vins\n",
      "\n",
      "(' articles parlant nutrition ou vins\\n', ' nutrition ou vins\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  sur l'aéronautique\n",
      "\n",
      "(\" sur l'aéronautique\\n\", \" l'aéronautique\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  traitant serious game et réalité virtuelle\n",
      "\n",
      "(' traitant serious game et réalité virtuelle\\n', ' serious game et réalité virtuelle\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  traitant d'informatique ou reseaux\n",
      "\n",
      "(\" traitant d'informatique ou reseaux\\n\", \" d'informatique ou reseaux\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  mentionnant laboratoire\n",
      "\n",
      "(' mentionnant laboratoire\\n', ' laboratoire\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  portant sur recherche\n",
      "\n",
      "(' portant sur recherche\\n', ' recherche\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  sur plasturgie\n",
      "\n",
      "(' sur plasturgie\\n', ' plasturgie\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  portent à fois sur nanotechnologies et microsatellites\n",
      "\n",
      "(' portent à fois sur nanotechnologies et microsatellites\\n', ' nanotechnologies et microsatellites\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  liés à recherche scientifique  qui parlent d'apprentissage et \n",
      "\n",
      "(\" liés à recherche scientifique  qui parlent d'apprentissage et \\n\", \" d'apprentissage et \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  dans domaine industriel et  parlant cerveau\n",
      "\n",
      "(' dans domaine industriel et  parlant cerveau\\n', ' cerveau\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  sur cnrs et l'innovation  sur avions\n",
      "\n",
      "(\" sur cnrs et l'innovation  sur avions\\n\", \" cnrs et l'innovation  sur avions\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  qui portent sur l'alimentation    parlant smartphones\n",
      "\n",
      "(\" qui portent sur l'alimentation    parlant smartphones\\n\", \" l'alimentation    parlant smartphones\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant projet européen  \n",
      "\n",
      "(' parlant projet européen  \\n', ' projet européen  \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant neurobiologie\n",
      "\n",
      "(' parlant neurobiologie\\n', ' neurobiologie\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  possédant mot france \n",
      "\n",
      "(' possédant mot france \\n', ' france \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlent l'environnement \n",
      "\n",
      "(\" parlent l'environnement \\n\", \" l'environnement \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  contenant mots voitures et électrique \n",
      "\n",
      "(' contenant mots voitures et électrique \\n', 's voitures et électrique \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:     qui parlent microbiologie \n",
      "\n",
      "('    qui parlent microbiologie \\n', ' microbiologie \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlent d'informatique ou télécommunications\n",
      "\n",
      "(\" parlent d'informatique ou télécommunications\\n\", \" d'informatique ou télécommunications\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  parlent l'écologie en france\n",
      "\n",
      "(\" parlent l'écologie en france\\n\", \" l'écologie en france\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  parlent réalité virtuelle \n",
      "\n",
      "(' parlent réalité virtuelle \\n', ' réalité virtuelle \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  trouve-t-on articles sur l'alimentation \n",
      "\n",
      "(\" trouve-t-on articles sur l'alimentation \\n\", \" l'alimentation \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent soit cnrs, soit grandes écoles, mais pas centrale paris\n",
      "\n",
      "(' qui parlent soit cnrs, soit grandes écoles, mais pas centrale paris\\n', ' soit cnrs, soit grandes écoles, mais pas centrale paris\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parle biologie et qui  qui parlent d'innovations technologiques \n",
      "\n",
      "(\" qui parle biologie et qui  qui parlent d'innovations technologiques \\n\", \" d'innovations technologiques \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:    provenant et  à propos fleurs ou arbres\n",
      "\n",
      "('   provenant et  à propos fleurs ou arbres\\n', ' fleurs ou arbres\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  donc et qui contiennent mots chercheurs et paris\n",
      "\n",
      "(' donc et qui contiennent mots chercheurs et paris\\n', 's chercheurs et paris\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent sénégal\n",
      "\n",
      "(' qui parlent sénégal\\n', ' sénégal\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent d'innovation\n",
      "\n",
      "(\" qui parlent d'innovation\\n\", \" d'innovation\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:    qui contiennent mots ecole et polytechnique\n",
      "\n",
      "('   qui contiennent mots ecole et polytechnique\\n', 's ecole et polytechnique\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  provenant \n",
      "\n",
      "None\n",
      "-------------------------------------------------\n",
      "requete:  qui  laurent lagrost est-il cité \n",
      "\n",
      "None\n",
      "-------------------------------------------------\n",
      "requete:  évoquent ville grenoble \n",
      "\n",
      "(' évoquent ville grenoble \\n', ' ville grenoble \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant drones\n",
      "\n",
      "(' parlant drones\\n', ' drones\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant molécules\n",
      "\n",
      "(' parlant molécules\\n', ' molécules\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  \n",
      "\n",
      "None\n",
      "-------------------------------------------------\n",
      "requete:  parlant d'université\n",
      "\n",
      "(\" parlant d'université\\n\", \" d'université\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  dont \n",
      "\n",
      "None\n",
      "-------------------------------------------------\n",
      "requete:    dont mais qui ne parlent pas d'ingénieurs\n",
      "\n",
      "(\"   dont mais qui ne parlent pas d'ingénieurs\\n\", \" pas d'ingénieurs\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  dont et qui évoquent médecine\n",
      "\n",
      "(' dont et qui évoquent médecine\\n', ' médecine\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:       et  sur changement climatique  parlent d'aviation et ont été  \n",
      "\n",
      "(\"      et  sur changement climatique  parlent d'aviation et ont été  \\n\", \" d'aviation et ont été  \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:       qui parlent ville paris \n",
      "\n",
      "('      qui parlent ville paris \\n', ' ville paris \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  impliquant cnrs et qui parlent chimie\n",
      "\n",
      "(' impliquant cnrs et qui parlent chimie\\n', ' chimie\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui mentionnent fink\n",
      "\n",
      "(' qui mentionnent fink\\n', ' fink\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  parlent france et l'allemagne \n",
      "\n",
      "(\" parlent france et l'allemagne \\n\", \" france et l'allemagne \\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  parlant l'argentine ou brésil\n",
      "\n",
      "(\" parlant l'argentine ou brésil\\n\", \" l'argentine ou brésil\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent l'hydravion\n",
      "\n",
      "(\" qui parlent l'hydravion\\n\", \" l'hydravion\\n\", None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent fauteuil roulant et qui ont pour \n",
      "\n",
      "(' qui parlent fauteuil roulant et qui ont pour \\n', ' fauteuil roulant et qui ont pour \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui sont parlent « chrono-environnement »\n",
      "\n",
      "(' qui sont parlent « chrono-environnement »\\n', ' « chrono-environnement »\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent robots et chirurgiens \n",
      "\n",
      "(' qui parlent robots et chirurgiens \\n', ' robots et chirurgiens \\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent systmes embarqués et non pas robotique\n",
      "\n",
      "(' qui parlent systmes embarqués et non pas robotique\\n', ' systmes embarqués et non pas robotique\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:  qui parlent alimentations ou agricultures\n",
      "\n",
      "(' qui parlent alimentations ou agricultures\\n', ' alimentations ou agricultures\\n', None)\n",
      "-------------------------------------------------\n",
      "requete:   \n",
      "None\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(\"post_dates.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()   \n",
    "\n",
    "with open(\"post_mots.txt\", 'w', encoding='utf-8') as f2:\n",
    "    for requete in list_of_strings:  \n",
    "        print(\"requete:\", requete)\n",
    "        print(identifie_mots_cles(requete, mots_cles_articles))    \n",
    "        print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f93bc49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "sous_text:  systèmes embarqués dans \n",
      "\n",
      "----------------------\n",
      "sous_text: systèmes embarqués dans \n",
      "\n",
      "----------------------\n",
      "sous_text:  cuisine moléculaire\n",
      "\n",
      "----------------------\n",
      "sous_text: cuisine moléculaire\n",
      "\n",
      "----------------------\n",
      "sous_text:  réalité virtuelle \n",
      "\n",
      "----------------------\n",
      "sous_text:  d'airbus ou projet taxibot\n",
      "\n",
      "----------------------\n",
      "sous_text: d'airbus ou projet taxibot\n",
      "\n",
      "----------------------\n",
      "sous_text:  tennis\n",
      "\n",
      "----------------------\n",
      "sous_text: tennis\n",
      "\n",
      "----------------------\n",
      "sous_text:  lune\n",
      "\n",
      "----------------------\n",
      "sous_text:  etats-unis \n",
      "\n",
      "----------------------\n",
      "sous_text:  d'innovation\n",
      "\n",
      "----------------------\n",
      "sous_text:  russie ou japon \n",
      "\n",
      "----------------------\n",
      "sous_text:  l'enseignement\n",
      "\n",
      "----------------------\n",
      "sous_text:  santé\n",
      "\n",
      "----------------------\n",
      "sous_text:  nutrition ou vins\n",
      "\n",
      "----------------------\n",
      "sous_text:  l'aéronautique\n",
      "\n",
      "----------------------\n",
      "sous_text:  serious game et réalité virtuelle\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'informatique ou reseaux\n",
      "\n",
      "----------------------\n",
      "sous_text:  laboratoire\n",
      "\n",
      "----------------------\n",
      "sous_text:  recherche\n",
      "\n",
      "----------------------\n",
      "sous_text:  sur recherche\n",
      "\n",
      "----------------------\n",
      "sous_text:  plasturgie\n",
      "\n",
      "----------------------\n",
      "sous_text:  nanotechnologies et microsatellites\n",
      "\n",
      "----------------------\n",
      "sous_text:  à fois sur nanotechnologies et microsatellites\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'apprentissage et \n",
      "\n",
      "----------------------\n",
      "sous_text:  à recherche scientifique  qui parlent d'apprentissage et \n",
      "\n",
      "----------------------\n",
      "sous_text: d'apprentissage et \n",
      "\n",
      "----------------------\n",
      "sous_text:  cerveau\n",
      "\n",
      "----------------------\n",
      "sous_text:  industriel et  parlant cerveau\n",
      "\n",
      "----------------------\n",
      "sous_text:  cnrs et l'innovation  sur avions\n",
      "\n",
      "----------------------\n",
      "sous_text:  l'alimentation    parlant smartphones\n",
      "\n",
      "----------------------\n",
      "sous_text:  smartphones\n",
      "\n",
      "----------------------\n",
      "sous_text:  sur l'alimentation    parlant smartphones\n",
      "\n",
      "----------------------\n",
      "sous_text:  projet européen  \n",
      "\n",
      "----------------------\n",
      "sous_text:  neurobiologie\n",
      "\n",
      "----------------------\n",
      "sous_text:  france \n",
      "\n",
      "----------------------\n",
      "sous_text:  l'environnement \n",
      "\n",
      "----------------------\n",
      "sous_text: l'environnement \n",
      "\n",
      "----------------------\n",
      "sous_text: voitures et électrique \n",
      "\n",
      "----------------------\n",
      "sous_text:  voitures et électrique \n",
      "\n",
      "----------------------\n",
      "sous_text:  microbiologie \n",
      "\n",
      "----------------------\n",
      "sous_text: microbiologie \n",
      "\n",
      "----------------------\n",
      "sous_text:  d'informatique ou télécommunications\n",
      "\n",
      "----------------------\n",
      "sous_text: d'informatique ou télécommunications\n",
      "\n",
      "----------------------\n",
      "sous_text:  l'écologie en france\n",
      "\n",
      "----------------------\n",
      "sous_text: l'écologie en france\n",
      "\n",
      "----------------------\n",
      "sous_text:  réalité virtuelle \n",
      "\n",
      "----------------------\n",
      "sous_text: réalité virtuelle \n",
      "\n",
      "----------------------\n",
      "sous_text:  l'alimentation \n",
      "\n",
      "----------------------\n",
      "sous_text:  soit cnrs, soit grandes écoles, mais pas centrale paris\n",
      "\n",
      "----------------------\n",
      "sous_text: soit cnrs, soit grandes écoles, mais pas centrale paris\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'innovations technologiques \n",
      "\n",
      "----------------------\n",
      "sous_text:  biologie et qui  qui parlent d'innovations technologiques \n",
      "\n",
      "----------------------\n",
      "sous_text:  fleurs ou arbres\n",
      "\n",
      "----------------------\n",
      "sous_text: chercheurs et paris\n",
      "\n",
      "----------------------\n",
      "sous_text:  chercheurs et paris\n",
      "\n",
      "----------------------\n",
      "sous_text:  sénégal\n",
      "\n",
      "----------------------\n",
      "sous_text: sénégal\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'innovation\n",
      "\n",
      "----------------------\n",
      "sous_text: d'innovation\n",
      "\n",
      "----------------------\n",
      "sous_text: ecole et polytechnique\n",
      "\n",
      "----------------------\n",
      "sous_text:  ecole et polytechnique\n",
      "\n",
      "----------------------\n",
      "sous_text:  ville grenoble \n",
      "\n",
      "----------------------\n",
      "sous_text:  drones\n",
      "\n",
      "----------------------\n",
      "sous_text:  molécules\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'université\n",
      "\n",
      "----------------------\n",
      "sous_text:  pas d'ingénieurs\n",
      "\n",
      "----------------------\n",
      "sous_text: pas d'ingénieurs\n",
      "\n",
      "----------------------\n",
      "sous_text:  médecine\n",
      "\n",
      "----------------------\n",
      "sous_text:  d'aviation et ont été  \n",
      "\n",
      "----------------------\n",
      "sous_text:  changement climatique  parlent d'aviation et ont été  \n",
      "\n",
      "----------------------\n",
      "sous_text: d'aviation et ont été  \n",
      "\n",
      "----------------------\n",
      "sous_text:  ville paris \n",
      "\n",
      "----------------------\n",
      "sous_text: ville paris \n",
      "\n",
      "----------------------\n",
      "sous_text:  chimie\n",
      "\n",
      "----------------------\n",
      "sous_text: chimie\n",
      "\n",
      "----------------------\n",
      "sous_text:  cnrs et qui parlent chimie\n",
      "\n",
      "----------------------\n",
      "sous_text:  fink\n",
      "\n",
      "----------------------\n",
      "sous_text:  france et l'allemagne \n",
      "\n",
      "----------------------\n",
      "sous_text: france et l'allemagne \n",
      "\n",
      "----------------------\n",
      "sous_text:  l'argentine ou brésil\n",
      "\n",
      "----------------------\n",
      "sous_text:  l'hydravion\n",
      "\n",
      "----------------------\n",
      "sous_text: l'hydravion\n",
      "\n",
      "----------------------\n",
      "sous_text:  fauteuil roulant et qui ont pour \n",
      "\n",
      "----------------------\n",
      "sous_text: fauteuil roulant et qui ont pour \n",
      "\n",
      "----------------------\n",
      "sous_text:  « chrono-environnement »\n",
      "\n",
      "----------------------\n",
      "sous_text: « chrono-environnement »\n",
      "\n",
      "----------------------\n",
      "sous_text:  robots et chirurgiens \n",
      "\n",
      "----------------------\n",
      "sous_text: robots et chirurgiens \n",
      "\n",
      "----------------------\n",
      "sous_text:  systmes embarqués et non pas robotique\n",
      "\n",
      "----------------------\n",
      "sous_text: systmes embarqués et non pas robotique\n",
      "\n",
      "----------------------\n",
      "sous_text:  alimentations ou agricultures\n",
      "\n",
      "----------------------\n",
      "sous_text: alimentations ou agricultures\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"post_dates.txt\", 'r', encoding='utf-8') as f1:\n",
    "    list_of_strings = f1.readlines()   \n",
    "\n",
    "with open(\"post_mots.txt\", 'w', encoding='utf-8') as f2:\n",
    "    for requete in list_of_strings:                \n",
    "        for mot in mots_cles_articles:\n",
    "            if mot in requete:\n",
    "                sous_text = requete[requete.find(mot) + len(mot):]\n",
    "                if sous_text[0] != \" \":\n",
    "                    sous_text = sous_text.split(\" \")[1:]\n",
    "                    sous_text = \" \".join(sous_text)\n",
    "                    print(\"----------------------\")\n",
    "                    print(\"sous_text:\", sous_text)\n",
    "                else:\n",
    "                    print(\"----------------------\")\n",
    "                    print(\"sous_text:\", sous_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032cb4a",
   "metadata": {},
   "source": [
    "TODO:\n",
    "    rajouter un moyen de nettoyer les résultats pour enlever les espaces inutiles et les \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac668d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Représentation structurée de la requête :\n",
      "{'mots_cles': [], 'rubrique': None, 'dates': {'debut': None, 'fin': None}, 'operateurs': [], 'titre': None, 'images': None}\n"
     ]
    }
   ],
   "source": [
    "def traiter_requete_sans_re(requete):   \n",
    "    # suppression des articles et ponctuations inutiless\n",
    "    requete = requete.lower()\n",
    "    requete = requete.replace(\"?\", \"\").replace(\".\", \"\").replace(\"’\", \"'\")\n",
    "    # Structure pour stocker les composants de la requête\n",
    "    resultats = {\n",
    "        \"return\": None,\n",
    "        \"mots_cles\": [],\n",
    "        \"rubrique\": None,\n",
    "        \"dates\": {\"debut\": None, \"fin\": None},\n",
    "        \"operateurs\": [],\n",
    "        \"titre\": None,\n",
    "        \"images\": None\n",
    "    }\n",
    "    # Extraction des mots-clés\n",
    "    requete, resultats[\"return\"] = identifie_return(requete, mots_cles_requete)\n",
    "    requete, resultats[\"images\"] = identifie_image(requete, mot_cles_images)\n",
    "    requete, resultats[\"rubrique\"], op_rubrique = identifie_rubrique(requete, mots_cles_rubrique)\n",
    "    if op_rubrique:\n",
    "        resultats[\"operateurs_rubrique\"] = op_rubrique\n",
    "    \n",
    "    #enlever les articles pour faciliter le traitement des mots clés\n",
    "    for article in articles_fr:\n",
    "        requete = requete.replace(\" \" + article + \" \", \" \")\n",
    "\n",
    "    #Extraction des titres\n",
    "    requete, resultat[\"titre\"], op_titre = identifie_titres(requete, mots_cles_titre)\n",
    "    if op_titre:\n",
    "        resultats[\"operateurs_titre\"] = op_titre\n",
    "    \n",
    "    # Extraction des dates (formats simples)\n",
    "    requete, resultats[\"dates\"] = identifie_dates(requete, mots_cles_dates)\n",
    "\n",
    "    # Extraction des mots clés restants\n",
    "    \n",
    "\n",
    "    return resultats\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    requete = input(\"Entrez votre requête en langage naturel : \")\n",
    "    resultat = traiter_requete_sans_re(requete)\n",
    "    print(\"Représentation structurée de la requête :\")\n",
    "    print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mots_cles_requests = [\n",
    "\"articles qui parlent \",\n",
    "\"articles qui parlent \",\n",
    "\"articles sur \",\n",
    "\"articles qui parlent \",\n",
    "\"articles qui parlent \",\n",
    "\"articles traitant \",\n",
    "\"parlant \",\n",
    "\"parlant \",\n",
    "\"sur \",\n",
    "\"Je cherche \",\n",
    "\"Article traitant \",\n",
    "\"Quels sont les articles traitant \",\n",
    "\"mentionnant \",\n",
    "\"portent à la fois sur \",\n",
    "\"articles liés à \",\n",
    "\n",
    "]\n",
    "\n",
    "operateurs = [\"ou\", \"et\"]\n",
    "\n",
    "\n",
    "titre_requests = [\"dont le titre contient\", ]\n",
    "dates_requests = [  \"parus entre \", \n",
    "                    \"de (date)\", \n",
    "                    \"publiés au\",\n",
    "                    \"publiés en\",\n",
    "                     ]\n",
    "rubrique_requests = [\"de la rubrique\", ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
